{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.fft\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import signal\n",
    "from scipy import integrate\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import butter, lfilter, filtfilt, savgol_filter\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft(data, fs):\n",
    "\n",
    "    N = len(data)\n",
    "    T = 1.0 / fs\n",
    "    \n",
    "    x = np.linspace(0.0, N*T, N)\n",
    "    y = scipy.fft.fft(data)\n",
    "\n",
    "    x_f = np.linspace(0.0, 1.0/(2.0*T), N // 2)\n",
    "    y_f = 2.0 / N * np.abs(y[:N // 2])\n",
    "\n",
    "    return x, y, x_f, y_f\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def low_pass_filter(x, cutoff, fs, order,type='float'):\n",
    "    if type == 'str':\n",
    "        x = [float(dx) for dx in x]\n",
    "    nyquist = fs / 2\n",
    "    b, a = butter(order, cutoff / nyquist)\n",
    "\n",
    "    filtered = filtfilt(b, a, x, method='gust')\n",
    "    if type == 'str':\n",
    "        return [str(s) for s in filtered]\n",
    "    else:\n",
    "        return filtered\n",
    "\n",
    "def NormaliseCrossCorrelation(a,v):\n",
    "    M = len(a)\n",
    "    N = len(v)\n",
    "\n",
    "    if type(a) is list: \n",
    "        a = np.array(a)\n",
    "    if type(v) is list:\n",
    "        v = np.array(v)\n",
    "    \n",
    "    v_mu = np.mean(v)\n",
    "\n",
    "    ncc_series = []\n",
    "    for i in range(M-N+1):\n",
    "        _a = a[i:i+N]\n",
    "        a_sum = _a - np.mean(_a)\n",
    "        v_sum = v - v_mu\n",
    "        nr = 1/N * np.sum(a_sum*v_sum) / np.sqrt(np.var(_a)*np.var(v))\n",
    "        ncc_series.append(nr)\n",
    "\n",
    "    return ncc_series\n",
    "\n",
    "def fix(data, max_len):\n",
    "    data_len = len(data) - 1\n",
    "    max_len = max_len - 1\n",
    "    dev = max_len - data_len\n",
    "    x = np.linspace(0, data_len, num = data_len + 1, endpoint=True)\n",
    "    y = np.array(data)\n",
    "    f = interp1d(x, y, kind = 'slinear')\n",
    "    xnew = np.linspace(0, data_len, num = data_len + dev + 1, endpoint=True)\n",
    "    return f(xnew)\n",
    "\n",
    "def Variability(a):\n",
    "    result = []\n",
    "    for j in range(len(a[1])):\n",
    "        col_array = [a[i][j] for i in range(len(a))]\n",
    "        result.append((max(col_array) - min(col_array)) / np.mean(col_array))\n",
    "    return result  \n",
    "\n",
    "def SampEn(L, m, r):\n",
    "    N = len(L)\n",
    "    B = 0.0\n",
    "    A = 0.0\n",
    "\n",
    "    # Split time series and save all templates of length m\n",
    "    xmi = np.array([L[i : i + m] for i in range(N - m)])\n",
    "    xmj = np.array([L[i : i + m] for i in range(N - m + 1)])\n",
    "\n",
    "    # Save all matches minus the self-match, compute B\n",
    "    B = np.sum([np.sum(np.abs(xmii - xmj).max(axis=1) <= r) - 1 for xmii in xmi])\n",
    "\n",
    "    # Similar for computing A\n",
    "    m += 1\n",
    "    xm = np.array([L[i : i + m] for i in range(N - m + 1)])\n",
    "\n",
    "    A = np.sum([np.sum(np.abs(xmi - xm).max(axis=1) <= r) - 1 for xmi in xm])\n",
    "\n",
    "    # Return SampEn\n",
    "    return -np.log(A / B)\n",
    "\n",
    "def CheckUpsideDown(signal):\n",
    "\n",
    "    signalU = -1 * signal\n",
    "\n",
    "    peaks, _ = find_peaks(signal[0:1000], height = 75, distance = 25)\n",
    "    peaksU, _ = find_peaks(signalU[0:1000], height = 75, distance = 25)\n",
    "\n",
    "    if len(peaks) > len(peaksU):\n",
    "        return signalU, True\n",
    "    else:\n",
    "        return signal, False\n",
    "\n",
    "def Outliers(data):\n",
    "    q1 = np.quantile(data, 0.25)  # Calculate the first quartile\n",
    "    q3 = np.quantile(data, 0.75)  # Calculate the third quartile\n",
    "    iqr = q3 - q1  # Calculate the interquartile range\n",
    "    threshold_low = q1 - 1.5 * iqr\n",
    "    threshold_high = q3 + 1.5 * iqr\n",
    "\n",
    "    outliers = np.where((data < threshold_low) | (data > threshold_high))[0]  # Calculate the index of outliers\n",
    "    if outliers.size > 0:\n",
    "        turnpoint = outliers[0] # Calculate the position of the first outlier\n",
    "        isTurn = True\n",
    "    else:\n",
    "        turnpoint = False\n",
    "        isTurn = False\n",
    "\n",
    "    return isTurn, turnpoint, outliers\n",
    "\n",
    "def FindMid(leftGyro, rightGyro, leftPeaks, rightPeaks):\n",
    "    \n",
    "    leftCutOffL = leftPeaks[1] # Find the target signal start, is middle of all signals\n",
    "    # leftCutOffR = leftPeaks[np.where(leftCutOffL <= leftPeaks)[0][5]]\n",
    "    leftCutOffR = leftCutOffL + 200\n",
    "    rightCutOffL = rightPeaks[np.where(leftCutOffL < rightPeaks)[0][0]]\n",
    "    # rightCutOffR = rightPeaks[np.where(leftCutOffL < rightPeaks)[0][5]]\n",
    "    rightCutOffR = rightCutOffL + 200\n",
    "\n",
    "    leftArray = leftPeaks[np.where((leftCutOffL <= leftPeaks) & (leftPeaks <= rightCutOffR))]\n",
    "    rightArray = rightPeaks[np.where((leftCutOffL <= rightPeaks) & (rightPeaks <= rightCutOffR))]\n",
    "\n",
    "    # 新的轉彎檢測 2023-03-10\n",
    "    isRightTurn, rightTurnPoint, _ = Outliers(rightGyro[rightArray]) # Detect if the right foot contains an outlier\n",
    "    isLeftTurn, leftTurnPoint, _ = Outliers(leftGyro[leftArray]) # Detect if the left foot contains an outlier\n",
    "\n",
    "    if isRightTurn == True:\n",
    "        turnPoint = rightArray[rightTurnPoint]\n",
    "\n",
    "    if isLeftTurn == True:\n",
    "        turnPoint = leftArray[leftTurnPoint]\n",
    "\n",
    "    if isLeftTurn == True or isRightTurn == True:    \n",
    "        leftCutOffL = leftPeaks[np.where(turnPoint < leftPeaks)[0][0]]\n",
    "        # leftCutOffR = leftPeaks[np.where(turnPoint < leftPeaks)[0][5]]\n",
    "        leftCutOffR = leftCutOffL + 650\n",
    "        rightCutOffL = rightPeaks[np.where(leftCutOffL < rightPeaks)[0][0]]\n",
    "        # rightCutOffR = rightPeaks[np.where(leftCutOffL < rightPeaks)[0][5]]\n",
    "        rightCutOffR = rightCutOffL + 650\n",
    "        isTurn = True\n",
    "    else:\n",
    "        isTurn = False\n",
    "\n",
    "    # # 舊的轉彎檢測\n",
    "    # isTurn = False\n",
    "    # isLeftTurn = False\n",
    "    # isRightTurn = False\n",
    "    # leftMean = np.mean(leftGyro[leftArray])\n",
    "    # rightMean = np.mean(rightGyro[rightArray])\n",
    "\n",
    "    # for i in rightArray:\n",
    "    #     if rightMean - rightGyro[i] > 80:\n",
    "    #         turnPoint = i\n",
    "    #         isRightTurn = True\n",
    "\n",
    "    # for i in leftArray:\n",
    "    #     if leftMean - leftGyro[i] > 80:\n",
    "    #         turnPoint = i\n",
    "    #         isLeftTurn = True\n",
    "    #         isTurn = True\n",
    "\n",
    "    return isTurn, leftCutOffL, leftCutOffR, rightCutOffL, rightCutOffR\n",
    "\n",
    "def FindValleys(data, peaks, direction):\n",
    "    valleys = []\n",
    "\n",
    "    if direction == 'right':\n",
    "        for i in range(len(peaks) - 1):\n",
    "            flag = 0 \n",
    "            for j in range(peaks[i], peaks[i + 1]):\n",
    "                slope = data[j + 1] - data[j]\n",
    "                \n",
    "                while slope > 0:\n",
    "                    valleys.append(j)\n",
    "                    flag = 1\n",
    "                    break\n",
    "\n",
    "                if flag == 1:\n",
    "                    break\n",
    "\n",
    "    if direction == 'left':\n",
    "        for i in range(len(peaks) - 1):\n",
    "            flag = 0 \n",
    "            for j in range(peaks[i], peaks[i - 1], -1):\n",
    "                slope = data[j] - data[j - 1]\n",
    "                \n",
    "                while slope < 0:\n",
    "                    valleys.append(j)\n",
    "                    flag = 1\n",
    "                    break\n",
    "\n",
    "                if flag == 1:\n",
    "                    break\n",
    "    return valleys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./c.台南立人里/投稿版本_data/低衰//102003.json\n",
      "leftSwingTime：0.40425999121651296\n",
      "leftSwingTime：0.3703807390817469\n",
      "./c.台南立人里/投稿版本_data/低衰//102005.json\n",
      "leftSwingTime：0.37933052434456926\n",
      "leftSwingTime：0.391304347826087\n",
      "./c.台南立人里/投稿版本_data/低衰//102007.json\n",
      "leftSwingTime：0.37380693487978733\n",
      "leftSwingTime：0.4\n",
      "./c.台南立人里/投稿版本_data/低衰//102009.json\n",
      "leftSwingTime：0.35833333333333334\n",
      "leftSwingTime：0.415929203539823\n",
      "./c.台南立人里/投稿版本_data/低衰//102013.json\n",
      "leftSwingTime：0.4351851851851852\n",
      "leftSwingTime：0.33636363636363636\n",
      "./c.台南立人里/投稿版本_data/低衰//102714.json\n",
      "leftSwingTime：0.3957677699403147\n",
      "leftSwingTime：0.4075940860215054\n",
      "./c.台南立人里/投稿版本_data/低衰//102715.json\n",
      "leftSwingTime：0.34775910364145657\n",
      "leftSwingTime：0.36893203883495146\n",
      "./c.台南立人里/投稿版本_data/低衰//102716.json\n",
      "leftSwingTime：0.375\n",
      "leftSwingTime：0.3854166666666667\n",
      "./c.台南立人里/投稿版本_data/低衰//102717.json\n",
      "leftSwingTime：0.41174554928354323\n",
      "leftSwingTime：0.37894736842105264\n",
      "./c.台南立人里/投稿版本_data/低衰//102718.json\n",
      "leftSwingTime：0.34855015673981193\n",
      "leftSwingTime：0.3999477533960293\n",
      "./c.台南立人里/投稿版本_data/低衰//102719.json\n",
      "leftSwingTime：0.376344688480502\n",
      "leftSwingTime：0.3862821948488242\n",
      "./c.台南立人里/投稿版本_data/低衰//102721.json\n",
      "leftSwingTime：0.35918220946915347\n",
      "leftSwingTime：0.36397707231040566\n",
      "./c.台南立人里/投稿版本_data/低衰//102723.json\n",
      "leftSwingTime：0.3659080767514502\n",
      "leftSwingTime：0.39753086419753086\n",
      "./c.台南立人里/投稿版本_data/低衰//102724.json\n",
      "leftSwingTime：0.3333333333333333\n",
      "leftSwingTime：0.4162008433853094\n",
      "./c.台南立人里/投稿版本_data/低衰//111027.json\n",
      "leftSwingTime：0.32407407407407407\n",
      "leftSwingTime：0.36538461538461536\n",
      "./c.台南立人里/投稿版本_data/低衰//111029.json\n",
      "leftSwingTime：0.3989247311827957\n",
      "leftSwingTime：0.383765778401122\n"
     ]
    }
   ],
   "source": [
    "rootpath = './c.台南立人里/投稿版本_data/低衰/'\n",
    "# rootpath = r'C:\\Users\\wwf\\Desktop\\Data\\00.Python\\四群資料\\SVM & KNN\\分類\\衰弱'\n",
    "all_file_name = os.listdir(rootpath)\n",
    "low_swing_time = []\n",
    "low_stance_time = []\n",
    "for _ in all_file_name:\n",
    "    name = _.split('.')[0]\n",
    "    path = f'{rootpath}/{_}'\n",
    "    print(path)\n",
    "    with open(path) as file:\n",
    "        Gait_Dict = json.load(file)\n",
    "    \n",
    "    # with open(Data, 'r') as f:\n",
    "    # Gait_Dict = json.loads(f.read())\n",
    "\n",
    "\n",
    "    # Access to the raw signal of each axis\n",
    "    leftGyroZRaw, leftCheck = CheckUpsideDown(np.array(Gait_Dict['LeftFootGyro']['z']))\n",
    "    leftAccXRaw = np.array(Gait_Dict['LeftFootAcc']['x'])\n",
    "\n",
    "    rightGyroZRaw, rightCheck = CheckUpsideDown(np.array(Gait_Dict['RightFootGyro']['z']))\n",
    "    rightAccXRaw = np.array(Gait_Dict['RightFootAcc']['x'])\n",
    "\n",
    "    leftRSSRaw = np.sqrt(np.array(Gait_Dict['LeftFootAcc']['x']) ** 2 + (np.array(Gait_Dict['LeftFootAcc']['y'])) ** 2 + np.array(Gait_Dict['LeftFootAcc']['z']) ** 2)\n",
    "    rightRSSRaw = np.sqrt(np.array(Gait_Dict['RightFootAcc']['x']) ** 2 + (np.array(Gait_Dict['RightFootAcc']['y'])) ** 2 + np.array(Gait_Dict['RightFootAcc']['z']) ** 2)\n",
    "\n",
    "    # Check for signal inversion, left foot\n",
    "    if leftCheck:\n",
    "        leftMagRaw = -1 * (np.array(Gait_Dict['LeftFootMag']['z']))\n",
    "    else:\n",
    "        leftMagRaw = np.array(Gait_Dict['LeftFootMag']['z'])\n",
    "\n",
    "    # Check for signal inversion, right foot\n",
    "    if rightCheck:\n",
    "        rightMagRaw = -1 * (np.array(Gait_Dict['RightFootMag']['z']))\n",
    "    else:\n",
    "        rightMagRaw = np.array(Gait_Dict['RightFootMag']['z'])\n",
    "\n",
    "    # Use SG filter for gyroscope signal and Euler angle signal\n",
    "    leftGyroZ = savgol_filter(leftGyroZRaw, 21, 3)\n",
    "    rightGyroZ = savgol_filter(rightGyroZRaw, 21, 3)\n",
    "\n",
    "    leftMag = savgol_filter(leftMagRaw, 21, 3)\n",
    "    rightMag = savgol_filter(rightMagRaw, 21, 3)\n",
    "\n",
    "    fs = 100\n",
    "\n",
    "    _, _, leftFFTx, leftFFTy = fft(leftRSSRaw, fs)\n",
    "\n",
    "    _, _, rightFFTx, rightFFTy = fft(rightRSSRaw, fs)\n",
    "\n",
    "    # Use Butterworth filter to the acceleration signal\n",
    "    # Parameters can use 20, 100, 8 or 15, 100, 4\n",
    "    leftRSS = low_pass_filter(leftRSSRaw, 15, fs, 4)\n",
    "    rightRSS = low_pass_filter(rightRSSRaw, 15, fs, 4)\n",
    "\n",
    "    # Mark gait feature points\n",
    "    leftToeOff, _ = rightFootFlat, _ = find_peaks(rightMag, distance = 80)\n",
    "    rightToeOff, _ = leftFootFlat, _ = find_peaks(leftMag, distance = 80)\n",
    "\n",
    "    leftInitialContact, _ = find_peaks(leftGyroZ, height = 100, distance = 80)\n",
    "    rightInitialContact, _ = find_peaks(rightGyroZ, height = 100, distance = 80)\n",
    "\n",
    "    leftFeetAdjacent = FindValleys(leftGyroZ, leftInitialContact, 'left')\n",
    "    rightFeetAdjacent = FindValleys(rightGyroZ, rightInitialContact, 'left')\n",
    "\n",
    "    leftTibiaVertical = FindValleys(leftMag, leftFootFlat, 'right')\n",
    "    rightTibiaVertical = FindValleys(rightMag, rightFootFlat, 'right')\n",
    "\n",
    "    # Confirm the signal band used\n",
    "    isTurn, stopLL, stopLR, stopRL, stopRR = FindMid(leftGyroZ, rightGyroZ, leftInitialContact, rightInitialContact)\n",
    "    # print(stopLL, stopLR, stopRL, stopRR)\n",
    "\n",
    "    # Confirm if the signal band consist turn\n",
    "    # print(isTurn)\n",
    "\n",
    "    # leftRSS_ = leftRSS[stopLL:stopLR]\n",
    "    # rightRSS_ = rightRSS[stopRL:stopRR]\n",
    "\n",
    "    leftFootLeftCutOff = np.where((stopLL <= leftInitialContact) & (leftInitialContact <= stopLR))[0][0]\n",
    "    leftFootRightCutOff = np.where((stopLL <= leftInitialContact) & (leftInitialContact <= stopLR))[0][-1] + 1\n",
    "    leftInitialContact_ = leftInitialContact[leftFootLeftCutOff:leftFootRightCutOff] - stopLL\n",
    "\n",
    "    rightFootLeftCutOff = np.where((stopRL <= rightInitialContact) & (rightInitialContact <= stopRR))[0][0]\n",
    "    rightFootRightCutOff = np.where((stopRL <= rightInitialContact) & (rightInitialContact <= stopRR))[0][-1] + 1\n",
    "    rightInitialContact_ = rightInitialContact[rightFootLeftCutOff:rightFootRightCutOff] - stopRL\n",
    "\n",
    "    leftToeOff_ = leftToeOff[np.where(leftToeOff < stopLL)[0][-1] : np.where(leftToeOff < stopLL)[0][-1] + len(leftInitialContact_)] - stopLL\n",
    "    leftFeetAdjacent_ = leftFeetAdjacent[np.where(leftFeetAdjacent < stopLL)[0][-1] : np.where(leftFeetAdjacent < stopLL)[0][-1] + len(leftInitialContact_)] - stopLL\n",
    "    leftTibiaVertical_ = leftTibiaVertical[np.where(leftTibiaVertical < stopLL)[0][-1] : np.where(leftTibiaVertical < stopLL)[0][-1] + len(leftInitialContact_)] - stopLL\n",
    "    leftFootFlat_ = leftFootFlat[np.where(leftFootFlat < stopLL)[0][-1] : np.where(leftFootFlat < stopLL)[0][-1] + len(leftInitialContact_)] - stopLL\n",
    "\n",
    "    rightToeOff_ = rightToeOff[np.where(rightToeOff < stopRL)[0][-1] : np.where(rightToeOff < stopRL)[0][-1] + len(rightInitialContact_)] - stopRL\n",
    "    rightFeetAdjacent_ = rightFeetAdjacent[np.where(rightFeetAdjacent < stopRL)[0][-1] : np.where(rightFeetAdjacent < stopRL)[0][-1] + len(rightInitialContact_)] - stopRL\n",
    "    rightTibiaVertical_ = rightTibiaVertical[np.where(rightTibiaVertical < stopRL)[0][-1] : np.where(rightTibiaVertical < stopRL)[0][-1] + len(rightInitialContact_)] - stopRL\n",
    "    rightFootFlat_ = rightFootFlat[np.where(rightFootFlat < stopRL)[0][-1] : np.where(rightFootFlat < stopRL)[0][-1] + len(rightInitialContact_)] - stopRL\n",
    "\n",
    "    # Calculate step time and swing time ratio\n",
    "    leftSwingTime = np.mean((leftInitialContact_ - leftToeOff_)[1:] / np.diff(leftToeOff_))\n",
    "    leftStepTime = 1 - leftSwingTime\n",
    "\n",
    "    rightSwingTime = np.mean((rightInitialContact_ - rightToeOff_)[1:] / np.diff(rightToeOff_))\n",
    "    rightStepTime = 1 - rightSwingTime\n",
    "\n",
    "    swingInGaitCycle = (leftSwingTime + rightSwingTime) / 2\n",
    "    stepInGaitCycle = (leftStepTime + rightStepTime) / 2\n",
    "    low_stance_time.append(stepInGaitCycle)\n",
    "    low_swing_time.append(swingInGaitCycle)\n",
    "    print(f'leftSwingTime：{leftSwingTime}')\n",
    "    print(f'leftSwingTime：{rightSwingTime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./c.台南立人里/投稿版本_data/高衰//102001.json\n",
      "leftSwingTime：0.35185185185185186\n",
      "leftSwingTime：0.4074074074074074\n",
      "./c.台南立人里/投稿版本_data/高衰//102002.json\n",
      "leftSwingTime：0.3706896551724138\n",
      "leftSwingTime：0.375\n",
      "./c.台南立人里/投稿版本_data/高衰//102004.json\n",
      "leftSwingTime：0.4020716685330347\n",
      "leftSwingTime：0.3494449583718779\n",
      "./c.台南立人里/投稿版本_data/高衰//102720.json\n",
      "leftSwingTime：0.3333333333333333\n",
      "leftSwingTime：0.43975903614457834\n",
      "./c.台南立人里/投稿版本_data/高衰//102722.json\n",
      "leftSwingTime：0.3707865168539326\n",
      "leftSwingTime：0.375\n",
      "./c.台南立人里/投稿版本_data/高衰//110325.json\n",
      "leftSwingTime：0.3963963963963964\n",
      "leftSwingTime：0.35454545454545455\n",
      "./c.台南立人里/投稿版本_data/高衰//111006.json\n",
      "leftSwingTime：nan\n",
      "leftSwingTime：nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jupiter\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\jupiter\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "rootpath = './c.台南立人里/投稿版本_data/高衰/'\n",
    "# rootpath = r'C:\\Users\\wwf\\Desktop\\Data\\00.Python\\四群資料\\SVM & KNN\\分類\\衰弱'\n",
    "all_file_name = os.listdir(rootpath)\n",
    "hight_swing_time = []\n",
    "hight_stance_time = []\n",
    "for _ in all_file_name:\n",
    "    name = _.split('.')[0]\n",
    "    path = f'{rootpath}/{_}'\n",
    "    print(path)\n",
    "    with open(path) as file:\n",
    "        Gait_Dict = json.load(file)\n",
    "    \n",
    "    # with open(Data, 'r') as f:\n",
    "    # Gait_Dict = json.loads(f.read())\n",
    "\n",
    "\n",
    "    # Access to the raw signal of each axis\n",
    "    leftGyroZRaw, leftCheck = CheckUpsideDown(np.array(Gait_Dict['LeftFootGyro']['z']))\n",
    "    leftAccXRaw = np.array(Gait_Dict['LeftFootAcc']['x'])\n",
    "\n",
    "    rightGyroZRaw, rightCheck = CheckUpsideDown(np.array(Gait_Dict['RightFootGyro']['z']))\n",
    "    rightAccXRaw = np.array(Gait_Dict['RightFootAcc']['x'])\n",
    "\n",
    "    leftRSSRaw = np.sqrt(np.array(Gait_Dict['LeftFootAcc']['x']) ** 2 + (np.array(Gait_Dict['LeftFootAcc']['y'])) ** 2 + np.array(Gait_Dict['LeftFootAcc']['z']) ** 2)\n",
    "    rightRSSRaw = np.sqrt(np.array(Gait_Dict['RightFootAcc']['x']) ** 2 + (np.array(Gait_Dict['RightFootAcc']['y'])) ** 2 + np.array(Gait_Dict['RightFootAcc']['z']) ** 2)\n",
    "\n",
    "    # Check for signal inversion, left foot\n",
    "    if leftCheck:\n",
    "        leftMagRaw = -1 * (np.array(Gait_Dict['LeftFootMag']['z']))\n",
    "    else:\n",
    "        leftMagRaw = np.array(Gait_Dict['LeftFootMag']['z'])\n",
    "\n",
    "    # Check for signal inversion, right foot\n",
    "    if rightCheck:\n",
    "        rightMagRaw = -1 * (np.array(Gait_Dict['RightFootMag']['z']))\n",
    "    else:\n",
    "        rightMagRaw = np.array(Gait_Dict['RightFootMag']['z'])\n",
    "\n",
    "    # Use SG filter for gyroscope signal and Euler angle signal\n",
    "    leftGyroZ = savgol_filter(leftGyroZRaw, 21, 3)\n",
    "    rightGyroZ = savgol_filter(rightGyroZRaw, 21, 3)\n",
    "\n",
    "    leftMag = savgol_filter(leftMagRaw, 21, 3)\n",
    "    rightMag = savgol_filter(rightMagRaw, 21, 3)\n",
    "\n",
    "    fs = 100\n",
    "\n",
    "    _, _, leftFFTx, leftFFTy = fft(leftRSSRaw, fs)\n",
    "\n",
    "    _, _, rightFFTx, rightFFTy = fft(rightRSSRaw, fs)\n",
    "\n",
    "    # Use Butterworth filter to the acceleration signal\n",
    "    # Parameters can use 20, 100, 8 or 15, 100, 4\n",
    "    leftRSS = low_pass_filter(leftRSSRaw, 15, fs, 4)\n",
    "    rightRSS = low_pass_filter(rightRSSRaw, 15, fs, 4)\n",
    "\n",
    "    # Mark gait feature points\n",
    "    leftToeOff, _ = rightFootFlat, _ = find_peaks(rightMag, distance = 80)\n",
    "    rightToeOff, _ = leftFootFlat, _ = find_peaks(leftMag, distance = 80)\n",
    "\n",
    "    leftInitialContact, _ = find_peaks(leftGyroZ, height = 100, distance = 80)\n",
    "    rightInitialContact, _ = find_peaks(rightGyroZ, height = 100, distance = 80)\n",
    "\n",
    "    leftFeetAdjacent = FindValleys(leftGyroZ, leftInitialContact, 'left')\n",
    "    rightFeetAdjacent = FindValleys(rightGyroZ, rightInitialContact, 'left')\n",
    "\n",
    "    leftTibiaVertical = FindValleys(leftMag, leftFootFlat, 'right')\n",
    "    rightTibiaVertical = FindValleys(rightMag, rightFootFlat, 'right')\n",
    "\n",
    "    # Confirm the signal band used\n",
    "    isTurn, stopLL, stopLR, stopRL, stopRR = FindMid(leftGyroZ, rightGyroZ, leftInitialContact, rightInitialContact)\n",
    "    # print(stopLL, stopLR, stopRL, stopRR)\n",
    "\n",
    "    # Confirm if the signal band consist turn\n",
    "    # print(isTurn)\n",
    "\n",
    "    # leftRSS_ = leftRSS[stopLL:stopLR]\n",
    "    # rightRSS_ = rightRSS[stopRL:stopRR]\n",
    "\n",
    "    leftFootLeftCutOff = np.where((stopLL <= leftInitialContact) & (leftInitialContact <= stopLR))[0][0]\n",
    "    leftFootRightCutOff = np.where((stopLL <= leftInitialContact) & (leftInitialContact <= stopLR))[0][-1] + 1\n",
    "    leftInitialContact_ = leftInitialContact[leftFootLeftCutOff:leftFootRightCutOff] - stopLL\n",
    "\n",
    "    rightFootLeftCutOff = np.where((stopRL <= rightInitialContact) & (rightInitialContact <= stopRR))[0][0]\n",
    "    rightFootRightCutOff = np.where((stopRL <= rightInitialContact) & (rightInitialContact <= stopRR))[0][-1] + 1\n",
    "    rightInitialContact_ = rightInitialContact[rightFootLeftCutOff:rightFootRightCutOff] - stopRL\n",
    "\n",
    "    leftToeOff_ = leftToeOff[np.where(leftToeOff < stopLL)[0][-1] : np.where(leftToeOff < stopLL)[0][-1] + len(leftInitialContact_)] - stopLL\n",
    "    leftFeetAdjacent_ = leftFeetAdjacent[np.where(leftFeetAdjacent < stopLL)[0][-1] : np.where(leftFeetAdjacent < stopLL)[0][-1] + len(leftInitialContact_)] - stopLL\n",
    "    leftTibiaVertical_ = leftTibiaVertical[np.where(leftTibiaVertical < stopLL)[0][-1] : np.where(leftTibiaVertical < stopLL)[0][-1] + len(leftInitialContact_)] - stopLL\n",
    "    leftFootFlat_ = leftFootFlat[np.where(leftFootFlat < stopLL)[0][-1] : np.where(leftFootFlat < stopLL)[0][-1] + len(leftInitialContact_)] - stopLL\n",
    "\n",
    "    rightToeOff_ = rightToeOff[np.where(rightToeOff < stopRL)[0][-1] : np.where(rightToeOff < stopRL)[0][-1] + len(rightInitialContact_)] - stopRL\n",
    "    rightFeetAdjacent_ = rightFeetAdjacent[np.where(rightFeetAdjacent < stopRL)[0][-1] : np.where(rightFeetAdjacent < stopRL)[0][-1] + len(rightInitialContact_)] - stopRL\n",
    "    rightTibiaVertical_ = rightTibiaVertical[np.where(rightTibiaVertical < stopRL)[0][-1] : np.where(rightTibiaVertical < stopRL)[0][-1] + len(rightInitialContact_)] - stopRL\n",
    "    rightFootFlat_ = rightFootFlat[np.where(rightFootFlat < stopRL)[0][-1] : np.where(rightFootFlat < stopRL)[0][-1] + len(rightInitialContact_)] - stopRL\n",
    "\n",
    "    # Calculate step time and swing time ratio\n",
    "    leftSwingTime = np.mean((leftInitialContact_ - leftToeOff_)[1:] / np.diff(leftToeOff_))\n",
    "    leftStepTime = 1 - leftSwingTime\n",
    "\n",
    "    rightSwingTime = np.mean((rightInitialContact_ - rightToeOff_)[1:] / np.diff(rightToeOff_))\n",
    "    rightStepTime = 1 - rightSwingTime\n",
    "\n",
    "    swingInGaitCycle = (leftSwingTime + rightSwingTime) / 2\n",
    "    stepInGaitCycle = (leftStepTime + rightStepTime) / 2\n",
    "    hight_stance_time.append(stepInGaitCycle)\n",
    "    hight_swing_time.append(swingInGaitCycle)\n",
    "    print(f'leftSwingTime：{leftSwingTime}')\n",
    "    print(f'leftSwingTime：{rightSwingTime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low_stance_time：[0.6126796348508701, 0.6146825639146719, 0.6130965325601063, 0.6128687315634218, 0.6142255892255892, 0.59831907201909, 0.641654428761796, 0.6197916666666666, 0.6046535411477021, 0.6257510449320793, 0.6186865583353369, 0.6384203591102204, 0.6182805295255095, 0.6252329116406787, 0.6552706552706553, 0.6086547452080411]\n",
      "low_stance_time：[0.38732036514912993, 0.3853174360853281, 0.3869034674398937, 0.3871312684365782, 0.38577441077441077, 0.40168092798091004, 0.358345571238204, 0.38020833333333337, 0.3953464588522979, 0.3742489550679206, 0.3813134416646631, 0.36157964088977956, 0.3817194704744905, 0.3747670883593214, 0.3447293447293447, 0.39134525479195886]\n",
      "hight_stance_time：[0.6203703703703703, 0.6271551724137931, 0.6242416865475436, 0.6134538152610443, 0.6271067415730337, 0.6245290745290746]\n",
      "hight_stance_time：[0.37962962962962965, 0.3728448275862069, 0.3757583134524563, 0.38654618473895586, 0.3728932584269663, 0.3754709254709255]\n",
      "swing_time：Ttest_indResult(statistic=0.6338026637016941, pvalue=0.5333930667062741)\n",
      "stance_time：Ttest_indResult(statistic=-0.6338026637017213, pvalue=0.5333930667062569)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "print(f'low_stance_time：{low_stance_time}')\n",
    "print(f'low_stance_time：{low_swing_time}')\n",
    "print(f'hight_stance_time：{hight_stance_time[0:-1]}')\n",
    "print(f'hight_stance_time：{hight_swing_time[0:-1]}')\n",
    "print(f'swing_time：{stats.ttest_ind(low_swing_time, hight_swing_time[0:-1], equal_var=False)}')\n",
    "print(f'stance_time：{stats.ttest_ind(low_stance_time, hight_stance_time[0:-1], equal_var=False)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
